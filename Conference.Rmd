---
title: "Conference"
author: "Richard G. Gardiner"
date: "4/7/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(glue)
library(tidytext)
library(gutenbergr)
library(wordcloud)
library(readxl)
```

Steps necessary:

```{r}
conference_raw <- read_excel("Conference Talks.xlsx")

numbers <- seq(1:100)


# unigram
conference <- conference_raw %>%
  unnest_tokens(word, Text) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!(word %in% c(numbers)))



# bigram
conference_bigram <- conference_raw %>%
  unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!(word1 %in% stop_words$word),
         !(word2 %in% stop_words$word),
         !(word1 %in% numbers),
         !(word2 %in% numbers))

conference %>%
  count(word, sort = TRUE) %>%
  top_n(10) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(x = "Number of Occurances", y = "Word",
       title = "Which Words Were Mentioned Most?")

conference %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```




2. make them unigrams
    - tidy text, unnest_tokens()
3. take out stop words
    - anti_join
4. word clouds
    - try it maybe for the global and then for each session
5. tf_idf
    - get unique words for people
6. topic modeling
    - Use this informed maybe by word clouds